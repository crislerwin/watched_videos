---
tags:
  - type/youtube
aliases: 
title: Elon Musk to Open Source Grok AI | «Murdering AI, Cloning Humans & AI Gods» OpenAI's Scott Aaronson
channel_name: Wes Roth
subscribers: 167000
length: 29:22
publish_date: 2024-03-11
chapters:
  - 00:00 OpenSource AI
  - 00:59 Scott Aaronson
  - 03:40 OpenAI Safety
  - 06:00 Possible AI Outcomes
  - 08:30 AI is JUST a...
  - 09:55 South Park & AI Watermarking
  - 12:23 Human vs AI «Genius»
  - 17:58 Value, Scarcity & Uniqueness
  - 21:28 Can you murder an AI? Can you clone a human?
  - 25:37 AI Safety & Robot Religion
  - 28:12 Philosopher Skinny Pete
hashtags: 
thumbnail: "![[1710264492969.jpg]]"
description: ""
note_created: 2024-03-12, 14:28
youtube_url: https://youtu.be/jrQW2eA8FSc
template-type: YouTube
template-version: "1.0"
created: 2024-03-12T14:28
updated: 2024-03-12T14:31
---

![[1710264492969.jpg]]

<iframe title="Elon Musk to Open Source Grok AI | «Murdering AI, Cloning Humans & AI Gods» OpenAI's Scott Aaronson" src="https://www.youtube.com/embed/jrQW2eA8FSc?feature=oembed" height="113" width="200" style="aspect-ratio: 1.76991 / 1; width: 100%; height: 100%;" allowfullscreen="" allow="fullscreen"></iframe>

SUMMARY:
Elon Musk announces xai, the company behind Grok, will open source Grok this week, joining other firms like Meta and Mistral in publishing chat bot code. Scott Aaronson, a theoretical computer scientist working at OpenAI, discusses AI safety, the potential future scenarios with advanced AI, and what makes humans unique.

IDEAS:
- Open sourcing AI models like Grok could accelerate AI development but also raises questions about AI safety and alignment
- There is growing mainstream concern and discussion about the potential for advanced AI to pose existential risks to humanity 
- Possible future AI scenarios range from AI progress fizzling out, to unaligned AI destroying humanity, to aligned AI ushering in a utopian future
- Many make "deflationary" claims that AI will never achieve certain capabilities, but fail to ask if humans are also "just" neurons and synapses
- Watermarking AI outputs could help identify AI-generated content but determined users could still circumvent it
- As AI improves at creative tasks, we may need to re-examine what makes human creativity and genius special and unique
- AI differs from humans in being inherently "rewindable" - you can generate many alternate outputs rather than a singular definitive work
- Humans' mortality, frailty and ephemeral nature may be a key remaining distinction from AI as other differences erode
- Destructively scanning/copying a human brain might not truly preserve personal identity due to the quantum no-cloning theorem
- One approach to AI safety could be instilling a "religion" in AI to respect and defer to humans' uniqueness and mortality

QUOTES:
- "There's a company that's building an AI that fills giant rooms, eats a town's worth of electricity, and has recently gained an astounding ability to converse like people."
- "Aren't you just a bundle of neurons and synapses? We could take that deflationary reductionistic stance about you also."
- "Talent hits a target that no one else can hit, but genius hits a target that no one else can see."
- "By its nature, AI, at least the way that we use it now, is inherently rewindable and repeatable and reproducible, which means that in a certain sense it never really commits to anything."
- "It would be humans' very ephemerality, frailty, mortality that would stand as this central source of their specialness relative to AI, after all of the other sources have fallen."
- "A fundamental fact in quantum mechanics is called the no-cloning theorem. It says there's no way to make a perfect copy of an unknown quantum state."
- "Perhaps via the usual methods like reinforcement learning and system prompts, the first commandment of this religion would be to value human specialness."

HABITS:
- Thinking deeply about the long-term implications and risks of advanced AI development
- Considering a wide range of possible future scenarios rather than just the most likely or desirable ones
- Challenging assumptions and claims about the limits of AI capabilities by comparing them to humans
- Exploring technical solutions like watermarking to help manage AI-generated content 
- Re-examining fundamental questions about the nature of intelligence, creativity, personal identity in light of AI progress
- Recognizing mortality and ephemerality as key traits that may continue to distinguish humans from AI
- Entertaining unorthodox ideas like instilling a "religion" in AI systems to respect human specialness

FACTS:
- Some AI companies like Meta, Mistl, and soon xai/Grock are open sourcing their AI models and code
- AI systems are rapidly gaining the ability to engage in open-ended conversation and assist with many intellectual tasks
- Scenarios for advanced AI range from existential catastrophe to unimaginable benefits for humanity
- The no-cloning theorem in quantum mechanics shows that arbitrary unknown quantum states cannot be perfectly copied
- Prominent AI pioneers like Geoffrey Hinton have considered restricting advanced AI to analog hardware for safety reasons
- South Park aired an episode about students using ChatGPT to cheat and a "wizard" detecting the AI-generated text

REFERENCES:
- Grock, an AI system developed by xai, which Elon Musk says will be open sourced
- Meta and Mistl, AI companies that have published their chat bot code 
- Scott Aaronson's blog where he writes about AI safety and other computer science topics
- The no-cloning theorem from quantum mechanics
- A South Park episode satirizing the use of AI writing tools like ChatGPT
- Geoffrey Hinton's suggestion to restrict advanced AI to analog hardware for safety reasons
- The science fiction idea of destructive teleportation that creates a copy of a person

RECOMMENDATIONS:
- Stay informed about developments in AI capabilities and open sourcing of AI models
- Consider the full range of possible future scenarios with advanced AI, both positive and negative
- Examine and challenge assumptions about the limits of AI compared to human intelligence
- Explore technical solutions like watermarking to help manage the impact of AI-generated content
- Contemplate how AI may force us to reexamine fundamental notions of intelligence, identity, and what makes humans unique
- Recognize and preserve the ephemeral and mortal nature of humans as a key distinction from copyable AI
- Be open to unorthodox ideas and approaches for instilling beneficial goals and behaviors in advanced AI systems
- Use science fiction as a tool for imagining and exploring future possibilities with transformative AI
- Have thoughtful discussions about the philosophical implications of AI for the human condition and our place in the universe
- Support research and initiatives aimed at developing safe and beneficial artificial intelligence that respects human agency